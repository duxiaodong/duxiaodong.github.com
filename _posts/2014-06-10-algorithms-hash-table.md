---
layout: post
title: 算法导论笔记(4)--散列表(Hash Table)
description: ""
category: "alogorithms"
tags: [hash table，alogorithms]
---
{% include JB/setup %}

##Index
* [直接寻址表(Direct-address tables)](#Direct-address tables)
* [散列表(Hash tables)](#Hash tables)
    * [链表法](#chaining)
    * [开放寻址法(open addressing)](#open addressing)
        * [线性探查(Linear probing)](#Linear probing)
        * [二次探查(quadratic probing)](#quadratic probing)
        * [双重散列(double hashing)](#double hashing)
* [散列函数(Hash functions)](#Hash functions)
    * [除法散列法(THe division method)](#The division method)
    * [乘法散列法(The multiplication method)](#The multiplication method)
    * [全域散列法(universal hashing)](#universal hashing)

当实际存储的关键字数目比全部的可能关键字总数要小时，采用散列表就成为直接数组寻址的一种有效代替，因为散列表使用一个长度与实际存储的关键字数目成比例的数组来存储。在散列表中，不是直接把关键字作为数组的下标，而是根据关键字计算出相应的下标。

## <span id="Direct-address tables">直接寻址表(Direct-address tables)</span>

当关键字的全域U比较小时，直接寻址是一种简单而有效的技术。假设某应用要用到一个动态集合，其中每个元素都是取自全域U={0,1,...,m-1}中的一个关键字，这里m不是一个很大的数。另外，假设没有两个元素具有相同的关键字。

为表示动态集合，我们用一个数组，或称为直接寻址表(direct-address table)，记为T[0...m-1]。其中每个位置，称为一个槽(slot)，对应全域U中的一个关键字。下图描述了该方法。槽k指向集合中一个关键字为k的元素。如果该集合中没有关键字为k的元素，则T[k]为NIL

![](/images/algo4-1.png)

直接寻址的几种操作实现起来比较简单：

![](/images/algo4-2.png)

上述每一个操作都只需O(1)时间

## <span id="Hash tables">散列表(Hash tables)</span>

直接寻址技术的缺点是非常明显的：如果全域U很大，则在一台标准的计算机可用内存容量中，要存储大小为|U|的一张表T也许不大实际，甚至不可能。还有，实际存储的关键字集合K相对于U来说可能很小，使得分配给T的大部分空间都将浪费掉。

当存储在字典中的关键字集合K比所有可能的关键字的全域U要小许多时，散列表需要的存储空间要比直接寻址表少的多。在散列方式下，元素存放在槽h(k)中即利用散列函数h，由关键字k计算出槽的位置。这里，函数h将关键字的全域U映射到散列表T[0...m-1]的槽位上。

`h:U-->{0,1,...,m-1}`

合理散列表的大小一般要比|u|小的多。下图表述了这个基本方法。散列函数缩小了数组下标的范围，即缩小了数组的大小，使其由|u|减小为m

![](/images/algo4-3.png)

这里存在一个问题：两个关键字可能映射到同一个槽中。我们称这种情形为冲突(collision)，解决冲突可以通过选择一个合适的散列函数h来做到这一点。但是，由于|U|>m，故至少有两个关键字其散列值相同，所以想要完全避免冲突是不可能的。因此一方面可以通过精心设计的散列函数来尽量减少冲突的次数，另一方面仍需要解决可能出现冲突的方法。

接下来介绍几种冲突解决的方法

### <span id="chaining">链表法</span>

在链接法中，把散列到同一槽中的所有元素都放在一个链表中，如下图所示，槽j中有一个指针，它指向存储所有散列到j的元素的链表的表头;如果不存在这样的元素，则槽j中为NIL。

![](/images/algo4-4.png)

在采用链接法解决冲突后，散列表T上的操作就很容易实现

![](/images/algo4-5.png)

在简单均匀散列的假设下，对于用链接法解决冲突的散列表，一次成功查找所需的平均时间为Θ(n+α),一次不成功查找的平均时间为Θ(n+α)

### <span id="open addressing">开放寻址法(open addressing)</span>

在开放寻址法中，所有的元素都存放在散列表里，也就是说，每个表项或包含动态集合的一个元素，或包含NIL，要查找某个元素时，要系统地检查所有的表项，直到找到所需的元素，或者最终查明该元素不在表中。在开放寻址法中，散列表可能会被填满，以至于不能插入任何新的元素。该方法导致的一个结果便是装载因子α绝对不超过1。

为了使用开发寻址法插入一个元素，需要连续地检查散列表，或称为探查(probe)，直到找到一个空槽来放置待插入的关键字为止。为了确定要探查哪些槽，我们将散列函数加以扩充，使之包含探查号(从0开始)以作为其第二个输入参数。这样，散列函数就变为

`h:U*{0,1,...,m-1} --> {0,1,...,m-1}`

对每一个关键字k，使用开放寻址法的探查序列(probe sequence)

`<h(k,0),h(k,1),...,h(k,m-1)>`

是<0,1,...,m-1>的一个排列，使得当散列表逐渐填满时，每一个表位最终都可以被考虑为用来插入新关键字的槽。

下面的伪代码中，假设散列表T中的元素为无卫星数据的关键字，关键字k等价于包含关键字k的元素。

HASH-INSERT过程以一个散列表T和一个关键字k为输入，其要么回复关键字k的存储槽位，要么因为散列表已满而返回错误标志。

![](/images/algo4-6.png)

查找关键字k的算法的探查序列与将k插入时的算法一样。因此，在查找过程中，碰到一个空槽时，查找算法就(非成功地)停止，应为如果k在表中，它就应该在此处，而不会是探查序列随后的位置上。过程HASH-SEARCH的输入为一个散列表T和一个关键字k，如果槽j中包含了关键字k，则返回j;如果k不在表T中，则返回NIL.

![](/images/algo4-7.png)

从开放寻址法的散列表中删除操作元素比较困难，当我们从槽i中删除关键字时，不能仅将NIL置于其中来标识它为空。因为在查找槽i之后插入的数据时，就会出现查找失败。有一个解决方法是把删除的槽i设置一个特定的值DELETED来代替NIL来标记该槽。但是，当我们使用特殊的值DELETED时，查找时间就不再依赖于装载因子α了。因此，在必须删除关键字的应用中，更常见的做法是采用链表法来解决冲突

有三种技术常用来计算开放寻址发中的探查序列:线性探测、二次探查和双重探查。

#### <span id="Linear probing">线性探查(Linear probing)</span>

给定一个普通的散列函数h':U-->{0,1,...,m-1}，称为辅助散列函数，线性探查方法采用的散列函数为

`h(k,i)=(h'(k)+i)modm, i = 0,1,...,m-1`

给定一个关键字k，首先探查槽T[h'(k)],即由辅助三列函数所给出的槽位。再探测T[h'(k)+1]，依次类推，直到槽T[m-1]。然后，又绕到槽T[0],T[1],...,直到最后探测到槽T[h'(k)-1]。

线性探测方法比较容易实现，但它存在着一个问题，称为一次群集。随着连续被占用的槽不断增加，平均查找时间也随之不断增加。集群现象很容易出现，这是因为当一个空槽前有i个满的槽时，该空槽下一个将被占用的概率是(i+1)/m。连续被占用的槽就会变得越来越长，因而平均查询时间也会越来越大。

#### <span id="quadratic probing">二次探查(quadratic probing)</span>

二次探查采用如下形式的散列函数：

`h(k,i)=(h'(k)+c₁i+c₁i+c₂i²)modm`

其中h'是一个辅助散列函数，c₁和c₂为正的辅助常数，i=0,1,...m-1。初始的探查位置为T[h/(k)]，后续的探查位置要加上一个偏移量，该偏移量以二次的方式依赖于探查序号i。这种探查方法的效果要比线性探查好很多，但是，为了能够充分利用散列表，c₁，c₂和m的值要受到限制。此外，如果两个关键字的初始探查位置相同，那么它们的探查序列也是相同的。这一性质可导致一种轻度的群集，称为二次群集。

#### <span id="double hashing">双重散列(double hashing)</span>

双重散列(double hashing)是用于开放寻址法的最好方法之一，因为它所产生的排列具有随机选择队列的许多特性。双重散列采用如下形式的散列函数:

`h(k,i)=(h₁(k)+ih₂(k))modm`

上图说明：双重散列法的插入。此处，散列表的大小为13，h₁(k)=kmod13，h₂(k)＝1+(kmod11)。因为14≡ 1(mod13)，14≡ 3(mod11)，故在探查了槽1和槽5，并发现它们被占用后，关键字14插入了槽9中

其中h₁和h₂均为辅助散列函数。初始探查位置为T[h₁(k)]，后续的探查位置是前一个位置加上偏移量h₂(k)模m。因此，不像线性探查或二次探查，这里的探查序列以两种不同方式依赖于关键字k，因为初始探查位置、偏移量或者两则都可能发生变化。下图给出了一个使用双重散列法进行插入的例子。

![](/images/algo4-8.png)

为了能偶查找整个散列表，值h₂(k)必须要与表的大小m互素。可以取m为2的幂。并设计一个总长生奇数的h₂;或者取m为素数，并设计一个总是返回较m小的正整数的函数h₂。例如，我们可以取m为素数，并取：

h₁(k) = kmodm ,h₂(k) = 1+(kmodm')

其中m'略小于m。

当m为素数或者2的幂时，双重散列法中用到了Θ(m²)中探查序列，而线性探查或二次探查中用了Θ(m)种，故前者是后两种方法的一次改进。

## <span id="Hash functions">散列函数(Hash functions)</span>

一个好的散列函数应满足简单均匀散列假设：每个关键字都被等可能地散列到m个槽位中的任何一个，并与其他关键字已散列到哪个槽位无关。

### <span id="The division method">除法散列法(THe division method)</span>

在用来设计散列函数的除法散列法中，通过取k除以m的余数，将关键字k映射到m个槽中的某一个上，即散列函数为:

`h(k)=k mod m`

当应用除法散列法时，要避免选择m的某些值，一个不太接近2的整数幂的素数，常常是m的一个较好的选择。

### <span id="The multiplication method">乘法散列法(The multiplication method)</span>

构造散列函数的乘法散列法包含两个步骤。第一步，用关键字k乘上常数A(0<A<1)，并提取kA的小数部分，第二步，用m乘以这个值，再向下取整。总之，散列函数为：

`h(k)=⌊m(kAmod1)⌋`

这里"kAmod1"是取kA的小数部分，即kA-⌊kA⌋.

乘法散列法的一个优点是对m的选择不是特别关键，一般选择它为2的某个幂次(m=2ᵖ,p为某个整数)。这个方法对任何的A值都适用，但对某些值效果更好。最佳的选择与待散列的数据的特征有关。Knuth认为，A约为(5^(1/2)-1)/2=0.6180339887……是个比较理想的值。

### <span id="universal hashing">全域散列法(universal hashing)</span>

任何一个特定的散列函数都可能将特定的n个关键字全部散列到同一个槽中，使得平均的检索时间为Θ(n)。为了避免这种情况，唯一有效的改进方法是随机地选择散列函数，使之独立与要存储的关键字。这种方法称为全域散列(universal hashing)。

全域散列在执行开始时，就从一组精心设计的函数中，随机地选择一个作为散列函数。因为随机地选择散列函数，算法在每一次执行时都会有所不同，甚至相同的输入都会如此。这样就可以确保对于任何输入，算法都具有较好的平均情况性能。

设ϰ为一组有限散列函数，它将给定的关键字全域U映射到{0,1,...m-1}中。这样的一组函数组称为全域的(universal)，如果对每一对不同的关键字k，l∈ U,满足h(k)=h(l)的散列函数h∈ ϰ的个数之多为|ϰ|/m。换句话说，如果从ϰ随机地选择一个散列函数，当关键字k‡l时，两者发生冲突的概率不大于1/m，这也正好是从集合{0,1,...,m-1}中独立地随机选择h(k)和h(l)时发生冲突的概率。
